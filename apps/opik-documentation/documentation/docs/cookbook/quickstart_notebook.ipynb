{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_DA4-McVXjF"
      },
      "source": [
        "# Quickstart notebook - Summarization\n",
        "\n",
        "In this notebook, we will look at how you can use Opik to track your LLM calls, chains and agents. We will introduce the concept of tracing and how to automate the evaluation of your LLM workflows.\n",
        "\n",
        "We will be using a technique called Chain of Density Summarization to summarize Arxiv papers. You can learn more about this technique in the [From Sparse to Dense: GPT-4 Summarization with Chain of Density Prompting](https://arxiv.org/abs/2309.04269) paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqw8vrFwVXjH"
      },
      "source": [
        "## Getting started\n",
        "\n",
        "We will first install the required dependencies and configure both Opik and OpenAI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PJuK1TOjVXjH",
        "outputId": "632ec3aa-6c1d-40ba-b5f1-5cc8eff46aae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opik in /usr/local/lib/python3.11/dist-packages (1.6.5)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.66.3)\n",
            "Requirement already satisfied: qiskit in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
            "Requirement already satisfied: caffe in /usr/local/lib/python3.11/dist-packages (0.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Requirement already satisfied: boto3-stubs>=1.34.110 in /usr/local/lib/python3.11/dist-packages (from boto3-stubs[bedrock-runtime]>=1.34.110->opik) (1.37.13)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from opik) (8.1.8)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from opik) (0.28.1)\n",
            "Requirement already satisfied: levenshtein<1.0.0 in /usr/local/lib/python3.11/dist-packages (from opik) (0.27.1)\n",
            "Requirement already satisfied: litellm in /usr/local/lib/python3.11/dist-packages (from opik) (1.63.8)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from opik) (2.8.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from opik) (2.10.6)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.11/dist-packages (from opik) (8.3.5)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from opik) (13.9.4)\n",
            "Requirement already satisfied: sentry_sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from opik) (2.22.0)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.11/dist-packages (from opik) (9.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from opik) (4.67.1)\n",
            "Requirement already satisfied: uuid6 in /usr/local/lib/python3.11/dist-packages (from opik) (2024.7.10)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from qiskit) (0.16.0)\n",
            "Requirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.11/dist-packages (from qiskit) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.11/dist-packages (from qiskit) (1.14.1)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.11/dist-packages (from qiskit) (1.13.1)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.11/dist-packages (from qiskit) (0.3.9)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from qiskit) (2.8.2)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from qiskit) (5.4.1)\n",
            "Requirement already satisfied: symengine<0.14,>=0.11 in /usr/local/lib/python3.11/dist-packages (from qiskit) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: botocore-stubs in /usr/local/lib/python3.11/dist-packages (from boto3-stubs>=1.34.110->boto3-stubs[bedrock-runtime]>=1.34.110->opik) (1.37.13)\n",
            "Requirement already satisfied: types-s3transfer in /usr/local/lib/python3.11/dist-packages (from boto3-stubs>=1.34.110->boto3-stubs[bedrock-runtime]>=1.34.110->opik) (0.11.4)\n",
            "Requirement already satisfied: mypy-boto3-bedrock-runtime<1.38.0,>=1.37.0 in /usr/local/lib/python3.11/dist-packages (from boto3-stubs[bedrock-runtime]>=1.34.110->opik) (1.37.7)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->opik) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->opik) (0.14.0)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in /usr/local/lib/python3.11/dist-packages (from levenshtein<1.0.0->opik) (3.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->opik) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->opik) (2.27.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.0.0->opik) (1.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.0->qiskit) (1.17.0)\n",
            "Requirement already satisfied: pbr>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from stevedore>=3.0.0->qiskit) (6.1.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.3->qiskit) (1.3.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from litellm->opik) (3.11.13)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.11/dist-packages (from litellm->opik) (8.6.1)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from litellm->opik) (3.1.6)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from litellm->opik) (4.23.0)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from litellm->opik) (0.9.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from litellm->opik) (0.21.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest->opik) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pytest->opik) (24.2)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest->opik) (1.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->opik) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->opik) (2.18.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=6.8.0->litellm->opik) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm->opik) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm->opik) (25.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm->opik) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm->opik) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm->opik) (0.23.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->opik) (0.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pbr>=2.0.0->stevedore>=3.0.0->qiskit) (75.1.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.7.0->litellm->opik) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm->opik) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm->opik) (1.3.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm->opik) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm->opik) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm->opik) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm->opik) (1.18.3)\n",
            "Requirement already satisfied: types-awscrt in /usr/local/lib/python3.11/dist-packages (from botocore-stubs->boto3-stubs>=1.34.110->boto3-stubs[bedrock-runtime]>=1.34.110->opik) (0.24.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers->litellm->opik) (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm->opik) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm->opik) (2024.10.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm->opik) (6.0.2)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'libhdf5-dev' instead of 'libhdf5-serial-dev'\n",
            "libsnappy-dev is already the newest version (1.1.8-1build3).\n",
            "libhdf5-dev is already the newest version (1.10.7+repack-4ubuntu2).\n",
            "libleveldb-dev is already the newest version (1.23-3build1).\n",
            "libprotobuf-dev is already the newest version (3.12.4-1ubuntu7.22.04.1).\n",
            "protobuf-compiler is already the newest version (3.12.4-1ubuntu7.22.04.1).\n",
            "libopencv-dev is already the newest version (4.5.4+dfsg-9ubuntu4+jammy0).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libboost-all-dev is already the newest version (1.74.0.3ubuntu7).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "%pip install -U opik openai qiskit caffe requests PyPDF2\n",
        "!sudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler\n",
        "!sudo apt-get install --no-install-recommends libboost-all-dev"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voDCR_oGVXjI"
      },
      "source": [
        "\n",
        "[Comet](https://www.comet.com/site?from=llm&utm_source=opik&utm_medium=colab&utm_content=langchain&utm_campaign=opik) provides a hosted version of the Opik platform, [simply create an account](https://www.comet.com/signup?from=llm&utm_source=opik&utm_medium=colab&utm_content=langchain&utm_campaign=opik) and grab you API Key.\n",
        "\n",
        "> You can also run the Opik platform locally, see the [installation guide](https://www.comet.com/docs/opik/self-host/overview/?from=llm&utm_source=opik&utm_medium=colab&utm_content=langchain&utm_campaign=opik) for more information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9NaKt0LyVXjJ",
        "outputId": "9101f66d-02b0-40b6-eea3-66739b1a6984",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "OPIK: Your Opik API key is available in your account settings, can be found at https://www.comet.com/api/my/settings/ for Opik cloud\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter your Opik API key:··········\n",
            "Do you want to use \"doditz\" workspace? (Y/n)y\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "OPIK: Configuration saved to file: /root/.opik.config\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import opik\n",
        "# Configure Opik\n",
        "opik.configure()"
      ]
    },
    {
      "source": [
        "!pip install --upgrade --force-reinstall nltk\n",
        "import nltk\n",
        "import cafe\n",
        "import qiskit\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import datalab\n",
        "import datascience\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "4NDkHLtrhfse",
        "outputId": "dc5e705f-e69e-4bd7-fb4a-4b0e1afaa5ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nltk\n",
            "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting click (from nltk)\n",
            "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting joblib (from nltk)\n",
            "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting regex>=2021.8.3 (from nltk)\n",
            "  Using cached regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "Collecting tqdm (from nltk)\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "Using cached regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
            "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
            "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Installing collected packages: tqdm, regex, joblib, click, nltk\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2024.11.6\n",
            "    Uninstalling regex-2024.11.6:\n",
            "      Successfully uninstalled regex-2024.11.6\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.4.2\n",
            "    Uninstalling joblib-1.4.2:\n",
            "      Successfully uninstalled joblib-1.4.2\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.1.8\n",
            "    Uninstalling click-8.1.8:\n",
            "      Successfully uninstalled click-8.1.8\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.9.1\n",
            "    Uninstalling nltk-3.9.1:\n",
            "      Successfully uninstalled nltk-3.9.1\n",
            "Successfully installed click-8.1.8 joblib-1.4.2 nltk-3.9.1 regex-2024.11.6 tqdm-4.67.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "joblib",
                  "nltk",
                  "regex",
                  "tqdm"
                ]
              },
              "id": "ac2ce867da474e889962deeecc71e5e2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'cafe'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-c69397b1bad1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install --upgrade --force-reinstall nltk'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcafe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mqiskit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cafe'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import random\n",
        "import threading\n",
        "import queue\n",
        "import qiskit\n",
        "import numpy as np\n",
        "import tensorflow as tr\n",
        "# --- Hypothetical QuaTAC QICMS Class (Replace with your actual implementation) ---\n",
        "# (Assumes similar implementation to the benchmark test)\n",
        "\n",
        "class QuaTAC_QICMS_System:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def process_query(self, query):\n",
        "        # 1. Process some query\n",
        "        return str(query) # Example Output\n",
        "        pass\n",
        "\n",
        " # --- 1. Test High Query Volumes ---\n",
        "def test_high_query_volume(qatac, query_count, num_threads):\n",
        "    \"\"\"Measure system performance under an extreme number of queries.\"\"\"\n",
        "\n",
        "    def worker(query_queue, results):\n",
        "        while not query_queue.empty():\n",
        "            try:\n",
        "                query = query_queue.get(timeout=0.1)  # Non-blocking get with timeout\n",
        "                start_time = time.time() #Start\n",
        "\n",
        "                result = qatac.process_query(query) #Process\n",
        "                end_time = time.time() #Stop\n",
        "                results.append(end_time - start_time) # Collect results\n",
        "            except queue.Empty:\n",
        "                break  # Exit loop if queue is empty\n",
        "\n",
        "    query_queue = queue.Queue()\n",
        "    for i in range(query_count):\n",
        "        query = f\"Query {i}\"  # Mock queries\n",
        "        query_queue.put(query)\n",
        "\n",
        "    threads = []\n",
        "    results = [] #Array Results\n",
        "\n",
        "    startTime = time.time() #Benchmark - Overall\n",
        "\n",
        "    for i in range(num_threads):\n",
        "        thread = threading.Thread(target=worker, args=(query_queue, results))\n",
        "        threads.append(thread)\n",
        "        thread.start()\n",
        "\n",
        "    for thread in threads:\n",
        "        thread.join()  # Wait for all threads to complete\n",
        "\n",
        "    endTime = time.time() #End Benchmark\n",
        "\n",
        "    # Output results and test parameters\n",
        "    print(\"\\nTest High Query Volume (Test A)\\n\")\n",
        "    print(f\"Number of Queries: {query_count}\\nNumber of Threads: {num_threads}\")\n",
        "    print(f\"Test time: {endTime - startTime}\\nTest Results:{results}\")\n",
        "# --- 2. Test Code Implemented ---\n",
        "\n",
        "# --- Parameters Setup -\n",
        "system = QuaTAC_QICMS_System()  # INIT QATAC QICMS. Needs to be init each time to ensure clean data\n",
        "testHigh = test_high_query_volume(system, query_count=2000, num_threads=5) # Simulate all threads to run test data\n",
        "\n",
        "\n",
        "# --- Execute: RUN Code --- #\n",
        "print(testHigh)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "_qQlYSx9BeSq",
        "outputId": "97e70764-cfdd-437f-e311-4d50bdf7e66f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'qiskit'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-484b70e08367>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mqiskit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'qiskit'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIbMcF2EVXjJ"
      },
      "source": [
        "## Implementing Chain of Density Summarization\n",
        "\n",
        "The idea behind this approach is to first generate a sparse candidate summary and then iteratively refine it with missing information without making it longer. We will start by defining two prompts:\n",
        "\n",
        "1. Iteration summary prompt: This prompt is used to generate and refine a candidate summary.\n",
        "2. Final summary prompt: This prompt is used to generate the final summary from the sparse set of candidate summaries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23l3mvQmVXjJ"
      },
      "outputs": [],
      "source": [
        "import opik\n",
        "\n",
        "ITERATION_SUMMARY_PROMPT = opik.Prompt(\n",
        "    name=\"Iteration Summary Prompt\",\n",
        "    prompt=\"\"\"\n",
        "Document: {{document}}\n",
        "Current summary: {{current_summary}}\n",
        "Instruction to focus on: {{instruction}}\n",
        "\n",
        "Generate a concise, entity-dense, and highly technical summary from the provided Document that specifically addresses the given Instruction.\n",
        "\n",
        "Guidelines:\n",
        "- Make every word count: If there is a current summary re-write it to improve flow, density and conciseness.\n",
        "- Remove uninformative phrases like \"the article discusses\".\n",
        "- The summary should become highly dense and concise yet self-contained, e.g. , easily understood without the Document.\n",
        "- Make sure that the summary specifically addresses the given Instruction\n",
        "\"\"\".rstrip().lstrip(),\n",
        ")\n",
        "\n",
        "FINAL_SUMMARY_PROMPT = opik.Prompt(\n",
        "    name=\"Final Summary Prompt\",\n",
        "    prompt=\"\"\"\n",
        "Given this summary: {{current_summary}}\n",
        "And this instruction to focus on: {{instruction}}\n",
        "Create an extremely dense, final summary that captures all key technical information in the most concise form possible, while specifically addressing the given instruction.\n",
        "\"\"\".rstrip().lstrip(),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jS0iHsztVXjK"
      },
      "source": [
        "We can now define the summarization chain by combining the two prompts. In order to track the LLM calls, we will use Opik's integration with OpenAI through the `track_openai` function and we will add the `@opik.track` decorator to each function so we can track the full chain and not just individual LLM calls:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0jEgHJpVXjK"
      },
      "outputs": [],
      "source": [
        "from opik.integrations.openai import track_openai\n",
        "from openai import OpenAI\n",
        "import opik\n",
        "\n",
        "# Use a dedicated quickstart endpoint, replace with your own OpenAI API Key in your own code\n",
        "openai_client = track_openai(\n",
        "    OpenAI(\n",
        "        base_url=\"https://odbrly0rrk.execute-api.us-east-1.amazonaws.com/Prod/\",\n",
        "        api_key=\"Opik-Quickstart\",\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "@opik.track\n",
        "def summarize_current_summary(\n",
        "    document: str,\n",
        "    instruction: str,\n",
        "    current_summary: str,\n",
        "    model: str = \"gpt-4o-mini\",\n",
        "):\n",
        "    prompt = ITERATION_SUMMARY_PROMPT.format(\n",
        "        document=document, current_summary=current_summary, instruction=instruction\n",
        "    )\n",
        "\n",
        "    response = openai_client.chat.completions.create(\n",
        "        model=model, max_tokens=4096, messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "@opik.track\n",
        "def iterative_density_summarization(\n",
        "    document: str,\n",
        "    instruction: str,\n",
        "    density_iterations: int,\n",
        "    model: str = \"gpt-4o-mini\",\n",
        "):\n",
        "    summary = \"\"\n",
        "    for iteration in range(1, density_iterations + 1):\n",
        "        summary = summarize_current_summary(document, instruction, summary, model)\n",
        "    return summary\n",
        "\n",
        "\n",
        "@opik.track\n",
        "def final_summary(instruction: str, current_summary: str, model: str = \"gpt-4o-mini\"):\n",
        "    prompt = FINAL_SUMMARY_PROMPT.format(\n",
        "        current_summary=current_summary, instruction=instruction\n",
        "    )\n",
        "\n",
        "    return (\n",
        "        openai_client.chat.completions.create(\n",
        "            model=model, max_tokens=4096, messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "        )\n",
        "        .choices[0]\n",
        "        .message.content\n",
        "    )\n",
        "\n",
        "\n",
        "@opik.track(project_name=\"Chain of Density Summarization\")\n",
        "def chain_of_density_summarization(\n",
        "    document: str,\n",
        "    instruction: str,\n",
        "    model: str = \"gpt-4o-mini\",\n",
        "    density_iterations: int = 2,\n",
        "):\n",
        "    summary = iterative_density_summarization(\n",
        "        document, instruction, density_iterations, model\n",
        "    )\n",
        "    final_summary_text = final_summary(instruction, summary, model)\n",
        "\n",
        "    return final_summary_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nb1-1CqkVXjK"
      },
      "source": [
        "Let's call the summarization chain with a sample document:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcQGLbpbVXjK"
      },
      "outputs": [],
      "source": [
        "import textwrap\n",
        "\n",
        "document = \"\"\"\n",
        "Artificial intelligence (AI) is transforming industries, revolutionizing healthcare, finance, education, and even creative fields. AI systems\n",
        "today are capable of performing tasks that previously required human intelligence, such as language processing, visual perception, and\n",
        "decision-making. In healthcare, AI assists in diagnosing diseases, predicting patient outcomes, and even developing personalized treatment plans.\n",
        "In finance, it helps in fraud detection, algorithmic trading, and risk management. Education systems leverage AI for personalized learning, adaptive\n",
        "testing, and educational content generation. Despite these advancements, ethical concerns such as data privacy, bias, and the impact of AI on employment\n",
        "remain. The future of AI holds immense potential, but also significant challenges.\n",
        "\"\"\"\n",
        "\n",
        "instruction = \"Summarize the main contributions of AI to different industries, and highlight both its potential and associated challenges.\"\n",
        "\n",
        "summary = chain_of_density_summarization(document, instruction)\n",
        "\n",
        "print(\"\\n\".join(textwrap.wrap(summary, width=80)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMVyG4daVXjL"
      },
      "source": [
        "Thanks to the `@opik.track` decorator and Opik's integration with OpenAI, we can now track the entire chain and all the LLM calls in the Opik UI:\n",
        "\n",
        "![Trace UI](https://raw.githubusercontent.com/comet-ml/opik/main/apps/opik-documentation/documentation/static/img/cookbook/chain_density_trace_cookbook.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfGjWvDYVXjL"
      },
      "source": [
        "## Automatting the evaluation process\n",
        "\n",
        "### Defining a dataset\n",
        "Now that we have a working chain, we can automate the evaluation process. We will start by defining a dataset of documents and instructions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ithug5vhVXjL"
      },
      "outputs": [],
      "source": [
        "import opik\n",
        "\n",
        "dataset_items = [\n",
        "    {\n",
        "        \"pdf_url\": \"https://arxiv.org/pdf/2301.00234\",\n",
        "        \"title\": \"A Survey on In-context Learning\",\n",
        "        \"instruction\": \"Summarize the key findings on the impact of prompt engineering in in-context learning.\",\n",
        "    },\n",
        "    {\n",
        "        \"pdf_url\": \"https://arxiv.org/pdf/2301.03728\",\n",
        "        \"title\": \"Scaling Laws for Generative Mixed-Modal Language Models\",\n",
        "        \"instruction\": \"How do scaling laws apply to generative mixed-modal models according to the paper?\",\n",
        "    },\n",
        "    {\n",
        "        \"pdf_url\": \"https://arxiv.org/pdf/2308.10792\",\n",
        "        \"title\": \"Instruction Tuning for Large Language Models: A Survey\",\n",
        "        \"instruction\": \"What are the major challenges in instruction tuning for large language models identified in the paper?\",\n",
        "    },\n",
        "    {\n",
        "        \"pdf_url\": \"https://arxiv.org/pdf/2302.08575\",\n",
        "        \"title\": \"Foundation Models in Natural Language Processing: A Survey\",\n",
        "        \"instruction\": \"Explain the role of foundation models in the current natural language processing landscape.\",\n",
        "    },\n",
        "    {\n",
        "        \"pdf_url\": \"https://arxiv.org/pdf/2306.13398\",\n",
        "        \"title\": \"Large-scale Multi-Modal Pre-trained Models: A Comprehensive Survey\",\n",
        "        \"instruction\": \"What are the cutting edge techniques used in multi-modal pre-training models?\",\n",
        "    },\n",
        "    {\n",
        "        \"pdf_url\": \"https://arxiv.org/pdf/2103.07492\",\n",
        "        \"title\": \"Continual Learning in Neural Networks: An Empirical Evaluation\",\n",
        "        \"instruction\": \"What are the main challenges of continual learning for neural networks according to the paper?\",\n",
        "    },\n",
        "    {\n",
        "        \"pdf_url\": \"https://arxiv.org/pdf/2304.00685v2\",\n",
        "        \"title\": \"Vision-Language Models for Vision Tasks: A Survey\",\n",
        "        \"instruction\": \"What are the most widely used vision-language models?\",\n",
        "    },\n",
        "    {\n",
        "        \"pdf_url\": \"https://arxiv.org/pdf/2303.08774\",\n",
        "        \"title\": \"GPT-4 Technical Report\",\n",
        "        \"instruction\": \"What are the main differences between GPT-4 and GPT-3.5?\",\n",
        "    },\n",
        "    {\n",
        "        \"pdf_url\": \"https://arxiv.org/pdf/2406.04744\",\n",
        "        \"title\": \"CRAG -- Comprehensive RAG Benchmark\",\n",
        "        \"instruction\": \"What was the approach to experimenting with different data mixtures?\",\n",
        "    },\n",
        "]\n",
        "\n",
        "client = opik.Opik()\n",
        "DATASET_NAME = \"arXiv Papers\"\n",
        "dataset = client.get_or_create_dataset(name=DATASET_NAME)\n",
        "dataset.insert(dataset_items)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUmKf05EVXjL"
      },
      "source": [
        "*Note:* Opik automatically deduplicates dataset items to make it easier to iterate on your dataset.\n",
        "\n",
        "### Defining the evaluation metrics\n",
        "\n",
        "Opik includes a [library of evaluation metrics](https://www.comet.com/docs/opik/evaluation/metrics/overview) that you can use to evaluate your chains. For this particular example, we will be using a custom metric that evaluates the relevance, conciseness and technical accuracy of each summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87vbw4h6VXjL"
      },
      "outputs": [],
      "source": [
        "from opik.evaluation.metrics import base_metric, score_result\n",
        "import json\n",
        "\n",
        "# We will define the response format so the output has the correct schema. You can also use structured outputs with Pydantic models for this.\n",
        "json_schema = {\n",
        "    \"type\": \"json_schema\",\n",
        "    \"json_schema\": {\n",
        "        \"name\": \"summary_evaluation_schema\",\n",
        "        \"schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"relevance\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"score\": {\n",
        "                            \"type\": \"integer\",\n",
        "                            \"minimum\": 1,\n",
        "                            \"maximum\": 5,\n",
        "                            \"description\": \"Score between 1-5 for how well the summary addresses the instruction\",\n",
        "                        },\n",
        "                        \"explanation\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"Brief explanation of the relevance score\",\n",
        "                        },\n",
        "                    },\n",
        "                    \"required\": [\"score\", \"explanation\"],\n",
        "                },\n",
        "                \"conciseness\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"score\": {\n",
        "                            \"type\": \"integer\",\n",
        "                            \"minimum\": 1,\n",
        "                            \"maximum\": 5,\n",
        "                            \"description\": \"Score between 1-5 for how concise the summary is while retaining key information\",\n",
        "                        },\n",
        "                        \"explanation\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"Brief explanation of the conciseness score\",\n",
        "                        },\n",
        "                    },\n",
        "                    \"required\": [\"score\", \"explanation\"],\n",
        "                },\n",
        "                \"technical_accuracy\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"score\": {\n",
        "                            \"type\": \"integer\",\n",
        "                            \"minimum\": 1,\n",
        "                            \"maximum\": 5,\n",
        "                            \"description\": \"Score between 1-5 for how accurately the summary conveys technical details\",\n",
        "                        },\n",
        "                        \"explanation\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"Brief explanation of the technical accuracy score\",\n",
        "                        },\n",
        "                    },\n",
        "                    \"required\": [\"score\", \"explanation\"],\n",
        "                },\n",
        "            },\n",
        "            \"required\": [\"relevance\", \"conciseness\", \"technical_accuracy\"],\n",
        "            \"additionalProperties\": False,\n",
        "        },\n",
        "    },\n",
        "}\n",
        "\n",
        "\n",
        "# Custom Metric: One template/prompt to extract 4 scores/results\n",
        "class EvaluateSummary(base_metric.BaseMetric):\n",
        "    # Constructor\n",
        "    def __init__(self, name: str):\n",
        "        self.name = name\n",
        "\n",
        "    def score(\n",
        "        self, summary: str, instruction: str, model: str = \"gpt-4o-mini\", **kwargs\n",
        "    ):\n",
        "        prompt = f\"\"\"\n",
        "            Summary: {summary}\n",
        "            Instruction: {instruction}\n",
        "\n",
        "            Evaluate the summary based on the following criteria:\n",
        "            1. Relevance (1-5): How well does the summary address the given instruction?\n",
        "            2. Conciseness (1-5): How concise is the summary while retaining key information?\n",
        "            3. Technical Accuracy (1-5): How accurately does the summary convey technical details?\n",
        "\n",
        "            Your response MUST be in the following JSON format:\n",
        "            {{\n",
        "                \"relevance\": {{\n",
        "                    \"score\": <int>,\n",
        "                    \"explanation\": \"<string>\"\n",
        "                }},\n",
        "            \"conciseness\": {{\n",
        "                \"score\": <int>,\n",
        "                \"explanation\": \"<string>\"\n",
        "                }},\n",
        "            \"technical_accuracy\": {{\n",
        "                \"score\": <int>,\n",
        "                \"explanation\": \"<string>\"\n",
        "                }}\n",
        "            }}\n",
        "\n",
        "            Ensure that the scores are integers between 1 and 5, and that the explanations are concise.\n",
        "        \"\"\"\n",
        "\n",
        "        response = openai_client.chat.completions.create(\n",
        "            model=model,\n",
        "            max_tokens=1000,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            response_format=json_schema,\n",
        "        )\n",
        "\n",
        "        eval_dict = json.loads(response.choices[0].message.content)\n",
        "\n",
        "        return [\n",
        "            score_result.ScoreResult(\n",
        "                name=\"summary_relevance\",\n",
        "                value=eval_dict[\"relevance\"][\"score\"],\n",
        "                reason=eval_dict[\"relevance\"][\"explanation\"],\n",
        "            ),\n",
        "            score_result.ScoreResult(\n",
        "                name=\"summary_conciseness\",\n",
        "                value=eval_dict[\"conciseness\"][\"score\"],\n",
        "                reason=eval_dict[\"conciseness\"][\"explanation\"],\n",
        "            ),\n",
        "            score_result.ScoreResult(\n",
        "                name=\"summary_technical_accuracy\",\n",
        "                value=eval_dict[\"technical_accuracy\"][\"score\"],\n",
        "                reason=eval_dict[\"technical_accuracy\"][\"explanation\"],\n",
        "            ),\n",
        "            score_result.ScoreResult(\n",
        "                name=\"summary_average_score\",\n",
        "                value=round(sum(eval_dict[k][\"score\"] for k in eval_dict) / 3, 2),\n",
        "                reason=\"The average of the 3 summary evaluation metrics\",\n",
        "            ),\n",
        "        ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vdfGu0zVXjM"
      },
      "source": [
        "### Create the task we want to evaluate\n",
        "\n",
        "We can now create the task we want to evaluate. In this case, we will have the dataset item as an input and return a dictionary containing the summary and the instruction so that we can use this in the evaluation metrics:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34_RTxcCVXjM"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import io\n",
        "from PyPDF2 import PdfReader\n",
        "from typing import Dict\n",
        "\n",
        "\n",
        "# Load and extract text from PDFs\n",
        "@opik.track\n",
        "def load_pdf(pdf_url: str) -> str:\n",
        "    # Download the PDF\n",
        "    response = requests.get(pdf_url)\n",
        "    pdf_file = io.BytesIO(response.content)\n",
        "\n",
        "    # Read the PDF\n",
        "    pdf_reader = PdfReader(pdf_file)\n",
        "\n",
        "    # Extract text from all pages\n",
        "    text = \"\"\n",
        "    for page in pdf_reader.pages:\n",
        "        text += page.extract_text()\n",
        "\n",
        "    # Truncate the text to 100000 characters as this is the maximum supported by OpenAI\n",
        "    text = text[:100000]\n",
        "    return text\n",
        "\n",
        "\n",
        "def evaluation_task(x: Dict):\n",
        "    text = load_pdf(x[\"pdf_url\"])\n",
        "    instruction = x[\"instruction\"]\n",
        "    model = MODEL\n",
        "    density_iterations = DENSITY_ITERATIONS\n",
        "\n",
        "    result = chain_of_density_summarization(\n",
        "        document=text,\n",
        "        instruction=instruction,\n",
        "        model=model,\n",
        "        density_iterations=density_iterations,\n",
        "    )\n",
        "\n",
        "    return {\"summary\": result}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYCiOujrVXjM"
      },
      "source": [
        "### Run the automated evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeZnI8E1VXjM"
      },
      "source": [
        "We can now use the `evaluate` method to evaluate the summaries in our dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3NUyqE7VXjM"
      },
      "outputs": [],
      "source": [
        "from opik.evaluation import evaluate\n",
        "\n",
        "MODEL = \"gpt-4o-mini\"\n",
        "DENSITY_ITERATIONS = 2\n",
        "\n",
        "experiment_config = {\n",
        "    \"iteration_summary_prompt\": ITERATION_SUMMARY_PROMPT,\n",
        "    \"final_summary_prompt\": FINAL_SUMMARY_PROMPT,\n",
        "    \"model\": MODEL,\n",
        "    \"density_iterations\": DENSITY_ITERATIONS,\n",
        "}\n",
        "\n",
        "res = evaluate(\n",
        "    dataset=dataset,\n",
        "    experiment_config=experiment_config,\n",
        "    task=evaluation_task,\n",
        "    scoring_metrics=[EvaluateSummary(name=\"summary-metrics\")],\n",
        "    prompt=ITERATION_SUMMARY_PROMPT,\n",
        "    project_name=\"Chain of Density Summarization\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IyjGUoVVXjM"
      },
      "source": [
        "The experiment results are now available in the Opik UI:\n",
        "\n",
        "![Trace UI](https://raw.githubusercontent.com/comet-ml/opik/main/apps/opik-documentation/documentation/static/img/cookbook/chain_density_experiment_cookbook.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gEEwRqtVXjN"
      },
      "source": [
        "## Comparing prompt templates\n",
        "\n",
        "We will update the iteration summary prompt and evaluate its impact on the evaluation metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBWohJtsVXjN"
      },
      "outputs": [],
      "source": [
        "import opik\n",
        "\n",
        "ITERATION_SUMMARY_PROMPT = opik.Prompt(\n",
        "    name=\"Iteration Summary Prompt\",\n",
        "    prompt=\"\"\"Document: {{document}}\n",
        "Current summary: {{current_summary}}\n",
        "Instruction to focus on: {{instruction}}\n",
        "\n",
        "Generate a concise, entity-dense, and highly technical summary from the provided Document that specifically addresses the given Instruction.\n",
        "\n",
        "Guidelines:\n",
        "1. **Maximize Clarity and Density**: Revise the current summary to enhance flow, density, and conciseness.\n",
        "2. **Eliminate Redundant Language**: Avoid uninformative phrases such as \"the article discusses.\"\n",
        "3. **Ensure Self-Containment**: The summary should be dense and concise, easily understandable without referring back to the document.\n",
        "4. **Align with Instruction**: Make sure the summary specifically addresses the given instruction.\n",
        "\n",
        "\"\"\".rstrip().lstrip(),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9o3ku5rVXjN"
      },
      "outputs": [],
      "source": [
        "from opik.evaluation import evaluate\n",
        "\n",
        "MODEL = \"gpt-4o-mini\"\n",
        "DENSITY_ITERATIONS = 2\n",
        "\n",
        "experiment_config = {\n",
        "    \"iteration_summary_prompt\": ITERATION_SUMMARY_PROMPT,\n",
        "    \"final_summary_prompt\": FINAL_SUMMARY_PROMPT,\n",
        "    \"model\": MODEL,\n",
        "    \"density_iterations\": DENSITY_ITERATIONS,\n",
        "}\n",
        "\n",
        "res = evaluate(\n",
        "    dataset=dataset,\n",
        "    experiment_config=experiment_config,\n",
        "    task=evaluation_task,\n",
        "    scoring_metrics=[EvaluateSummary(name=\"summary-metrics\")],\n",
        "    prompt=ITERATION_SUMMARY_PROMPT,\n",
        "    project_name=\"Chain of Density Summarization\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEZuu7imVXjN"
      },
      "source": [
        "You can now compare the results between the two experiments in the Opik UI:\n",
        "\n",
        "![Trace UI](https://raw.githubusercontent.com/comet-ml/opik/main/apps/opik-documentation/documentation/static/img/cookbook/chain_density_trace_comparison_cookbook.png)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}